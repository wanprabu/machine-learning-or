{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ee6fbc-98b7-4395-ab49-e5f31890aa56",
   "metadata": {},
   "source": [
    "# Regression\n",
    "In supervised learning, regression aims at predicting a continous numerical value using one or more independent features as input variables. It finds relationship between dependent variable (target) and independent variables (features). \n",
    "\n",
    "Different types of regression:\n",
    "1. Simple linear regression: assumes there is linear correlation between dependent and independent variables. \n",
    "2. Multiple linear regression: extends simple linear regression with multiple independent variables as predictors.\n",
    "3. Polynomial regression: used when there is non-linear relationship between dependent and independent variables.\n",
    "\n",
    "This notebook covers only simple and multiple linear regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e57a8b3-fe53-4c7b-98c9-55da6bf87df8",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3420ef-9e5c-45f7-9429-b35abb407cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88f4cf-b383-4d82-baf1-a81914ac4bec",
   "metadata": {},
   "source": [
    "We use **Student Performance** dataset from UCI ML repository. It contains data related to student achievement in secondary education, consisting of two subjects Mathematics (mat) and Portugese (por) language. The data has many features, including:\n",
    "* Demographic (e.g., `age`, `sex`, `address`)\n",
    "* Social and academic (e.g., `studytime`, `freetime`, `absences`)\n",
    "* Grades: `G1` - 1st grade, `G2` - 2nd grade, and `G3` - final grade\n",
    "\n",
    "For details of dataset information, including its features description, please visit the following website\n",
    "https://archive.ics.uci.edu/dataset/320/student+performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd3fe33-970b-4c92-aed5-4ff6e10f6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "studentDf = pd.read_csv('../dataset/student-mat.csv')\n",
    "studentDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae767915-9cc4-47c9-ab5e-e631eb6cd3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "studentDf.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de604cad-b816-4882-9b44-5dc57ebec033",
   "metadata": {},
   "outputs": [],
   "source": [
    "studentDf.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41db785-6c43-4242-a763-9f046491e94a",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "### Univariate analysis\n",
    "\n",
    "Plot distribution of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e89393-2c2e-4426-8d63-a30fe97dfbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 14))  \n",
    "i = 0\n",
    "for column in studentDf.select_dtypes(include=['number']):\n",
    "    sub = fig.add_subplot(4, 4, i + 1)\n",
    "    studentDf[column].plot(kind = 'hist')\n",
    "    sub.set_xlabel(column)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fe372e-d3ea-43d4-b0f3-807e19e54678",
   "metadata": {},
   "source": [
    "### Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645bade5-25b1-426a-8878-7d152a50976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation heat map\n",
    "sns.heatmap(studentDf.select_dtypes(include=['number']).corr(), annot=False, cmap='viridis', \n",
    "            cbar_kws={'label': 'Correlation Coefficient', \"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f173f-3a45-4e50-988c-b4f75a6732b9",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "Define predictor and target variables. Split dataset into train and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e27e7e-f64d-46b7-b988-ec81ce0fda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = studentDf['studytime'].to_numpy().reshape(-1, 1) # feature for predictor\n",
    "y = studentDf['G3'].to_numpy().reshape(-1, 1) # target to predict\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb6f82-1c72-4896-bb1d-4303770d818c",
   "metadata": {},
   "source": [
    "> Note that we had to perform `reshape` on the input data in order for the Linear Regression package to understand it correctly. Linear Regression expects a 2D-array as an input, where each row of the array corresponds to a vector of input features. In our case, since we have only one input - we need an array with shape N√ó1, where N is the dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f102a0-7041-4359-9852-c8cb402409ff",
   "metadata": {},
   "source": [
    "## Train the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed12a8-5ac0-4693-98e9-3383a59df5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# fit the ordinary linear regression (olr) model\n",
    "olr = LinearRegression()\n",
    "olr.fit(X_train, y_train)\n",
    "\n",
    "olr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e536632-6473-4713-87ca-4c410da81ee8",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a89396-bbeb-45f6-b888-1312aa5fc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using test dataset\n",
    "y_pred = olr.predict(X_test)\n",
    "\n",
    "# plot between true value and predicted value of G3 score\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([0, 25], [0, 25], '--k')\n",
    "plt.xlabel('True G3 score')\n",
    "plt.ylabel('Predicted G3 score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f3cad-ce3e-4a98-abbe-3c89d4cc49ff",
   "metadata": {},
   "source": [
    "> The selected `studytime` feature does not serve as a good linear relationship predictor for `G3` score. As shown in the plot, regardless the true value of `G3` the predicted values barely change as the actual grade change. This suggest that `studytime` does not capture enough information to predict the `G3` accurately. See further evaluation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6946c3-ac41-4493-a403-8b20d43ad79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MAPE: {mae/ y_test.mean() *100:.2f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "score = olr.score(X_train,y_train)\n",
    "print(f'Model determination: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91ecde-01d6-4b08-9821-2d710daaa42f",
   "metadata": {},
   "source": [
    "### üìä Interpretation of Results\n",
    "\n",
    "| Metric | Value | Meaning |\n",
    "|--------|-------|---------|\n",
    "| **MAE** | 3.63 | On average, the model's predictions are off by about 3.63 grade points. |\n",
    "| **MAPE** | 35.22 | The average percentage error is 35.22%, which is quite high. |\n",
    "| **MSE** | 21.85 | Squared error is high, indicating large deviations. |\n",
    "| **RMSE** | 4.67 | Root mean squared error confirms the average error magnitude. |\n",
    "| **R¬≤ Score** | 0.006 | The model explains only 0.6% of the variance in `G3`. Very poor fit. |\n",
    "| **Model Determination** | 0.0109 | Same as R¬≤, confirms very weak predictive power. |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### üß† What This Means?\n",
    "\n",
    "- Align with the prior plot, **`studytime` alone is a weak predictor** of final grade (`G3`).\n",
    "- The **high error metrics** (MAE, RMSE, MAPE) suggest the model is not reliable for prediction.\n",
    "- The R¬≤ score is close to zero, meaning the model barely explains any variation in the target.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç More about R¬≤\n",
    "\n",
    "**R¬≤** and **model determination** refer to the same metric, reflecting how well the model explains the variance in the target variable (`G3`). \n",
    "\n",
    "**Formula**:  \n",
    "  $$ R^2 = 1 - \\frac{\\text{SS}_{\\text{res}}}{\\text{SS}_{\\text{tot}}} $$\n",
    "where:\n",
    "  - $ \\text{SS}_{\\text{res}} $ = sum of squared residuals (errors)\n",
    "  - $ \\text{SS}_{\\text{tot}} $ = total sum of squares (variance of the target)\n",
    "\n",
    "**Interpretation**:\n",
    "  - R¬≤ = 1 ‚Üí perfect prediction\n",
    "  - R¬≤ = 0 ‚Üí model does no better than the mean\n",
    "  - R¬≤ < 0 ‚Üí model is worse than just predicting the mean\n",
    "\n",
    "As you may notice, the score of **R¬≤** and **model determination** are different. This is because they used different dataset. **R¬≤** was applied for **test data**, while **model determination** was calculated against **training data**. \n",
    "\n",
    "- Calculate both are essential for evaluating wheather the model overfits. **R¬≤** score on training will be higher than test in such case.\n",
    "- **R¬≤** score on test dataset indicates how well the model generalizes to unseen data.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db1e179-bf56-4f9c-956d-926a8a128a32",
   "metadata": {},
   "source": [
    "## Extract model insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd4f3c-b528-4b82-8416-4b097d532768",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Intercept: {olr.intercept_[0]:.2f}\")\n",
    "print(f\"Coefficient: {olr.coef_[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5f444-20ea-4f79-af59-05fb8252986c",
   "metadata": {},
   "source": [
    "> **Intercept** is the baseline value of the dependent variable when there is no contribution from the predictors.\n",
    "> The **coefficient is positive**, which makes sense: more study time tends to correlate with better grades, but the effect is small.\n",
    "> From the both values we can formulate linear model as follows:\n",
    "> $$ y = 9.28 + 0.57x_1$$\n",
    "> where $y$ denotes `G3` and $x_1$ refers to `studytime`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b96687-8a79-4989-bfa9-814497a59b11",
   "metadata": {},
   "source": [
    "## Train with another predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff53a0-635b-4d72-bddf-af558997b0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = studentDf['G1'].to_numpy().reshape(-1, 1) # feature for predictor\n",
    "y = studentDf['G3'].to_numpy().reshape(-1, 1) # target to predict\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# fit the ordinary linear regression (olr) model\n",
    "olr = LinearRegression()\n",
    "olr.fit(X_train, y_train)\n",
    "\n",
    "olr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a166c-e1da-43ca-a995-b54997b8802c",
   "metadata": {},
   "source": [
    "## Evaluate the model with new predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ff25c-6682-44d1-be15-755e5a359a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using test dataset\n",
    "y_pred = olr.predict(X_test)\n",
    "\n",
    "# plot between true value and predicted value of G3 score\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([0, 25], [0, 25], '--k')\n",
    "plt.xlabel('True G3 score')\n",
    "plt.ylabel('Predicted G3 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ca830-2044-40b9-a212-d9c3b2f8a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MAPE: {mae/ y_test.mean() *100:.2f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "score = olr.score(X_train,y_train)\n",
    "print(f'Model determination: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8289ba-e77a-4e68-8c4e-3973b9782690",
   "metadata": {},
   "source": [
    "### üìä Interpretation of Results\n",
    "\n",
    "The model now improved with better performance.\n",
    "\n",
    "| Metric | Value | Meaning |\n",
    "|--------|-------|---------|\n",
    "| **MAE** | 1.83 | On average, the model's predictions are off by about 1.83 grade points. |\n",
    "| **MAPE** | 17.75 | The average percentage error is 17.75%, which is reasonably acceptable. |\n",
    "| **MSE** | 6.66 | Squared error is approximately three times smaller than previous result. |\n",
    "| **RMSE** | 2.58 | Root mean squared error confirms the average error magnitude. |\n",
    "| **R¬≤ Score** | 0.6971 | The model explains 69% of the variance in `G3`. Such a good fit. |\n",
    "| **Model Determination** | 0.6165 | Same as R¬≤, confirms strong predictive power againts training data. |\n",
    "\n",
    "The small gap between **R¬≤** and **Model Determination** indicate the model did not suffer from overfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a221e8-0a6e-499b-a7b6-7070aa95c619",
   "metadata": {},
   "source": [
    "## New coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45169527-4483-4665-8324-e886fd5f7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Intercept: {olr.intercept_[0]:.2f}\")\n",
    "print(f\"Coefficient: {olr.coef_[0][0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9636ac-d138-4483-8e03-84544258f59d",
   "metadata": {},
   "source": [
    "> The baseline **intercept** value decreases significantly. Based on the value, it means that the model would predict `G3` to be -1.81 when the student `G1` score is 0.\n",
    "> \n",
    "> The **coefficient** tends to be a strong positive relationship with better `G3` grades. If the `G1` point increases 1 point, the `G3` score is predicted to increase by 1.11 points\n",
    "> \n",
    "> From the both values we can formulate linear model as follows:\n",
    "> $$ y = -1.81 + 1.11x_1$$\n",
    "> where $y$ denotes `G3` and $x_1$ refers to `G1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874318d0-8a1c-4bf1-b134-42d3715319dd",
   "metadata": {},
   "source": [
    "# Multiple Regression \n",
    "\n",
    "Let's now try to use all numeric features as predictor and see if they can improve the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cc2a3f-c57e-49a5-9363-9763a8311ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = studentDf.select_dtypes(include=['number']).drop('G3', axis=1) # select all numeric features except G3\n",
    "y = studentDf['G3'].to_numpy().reshape(-1, 1) # target to predict\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# fit the ordinary linear regression (olr) model\n",
    "multiple_reg_model = LinearRegression()\n",
    "multiple_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# predict using test dataset\n",
    "y_pred = multiple_reg_model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MAPE: {mae/ y_test.mean() *100:.2f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "\n",
    "score = multiple_reg_model.score(X_train,y_train)\n",
    "print(f'Model determination: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f4e96-d3bb-464b-8d72-4c3a8f3ec3e4",
   "metadata": {},
   "source": [
    "> Compared to the prior model, the new model has improved the performance by approximately **15%** based on the R¬≤ score when considering more features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d80b26-5705-4813-8d70-ee618c9ef3f5",
   "metadata": {},
   "source": [
    "### Extract new model insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d133b03-2f9b-427a-a592-538cf0181c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Intercept: {multiple_reg_model.intercept_[0]:.2f}\")\n",
    "\n",
    "coeff_df = pd.DataFrame({\"Feature\": X.columns, \"Coefficient\": multiple_reg_model.coef_[0]})\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87912a41-340c-44d4-b51f-e5da28d9f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by coefficients.\n",
    "coeff_df_sorted = coeff_df.sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "# Create plot.\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(coeff_df_sorted[\"Feature\"], coeff_df_sorted[\"Coefficient\"], color=\"blue\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance (Linear Regression Coefficients)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eafb38-a4a3-4c8c-a0f2-b0348cfdca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residuals.\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Create plots.\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Plot 1: Residuals Distribution.\n",
    "plt.subplot(1,2,1)\n",
    "sns.histplot(residuals, bins=30, kde=True, color=\"blue\")\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.xlabel(\"Residuals (y_actual - y_predicted)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "############# ------------------------- #############\n",
    "\n",
    "# Plot 2: Regression Fit (Actual vs Predicted).\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Perfect fit line\n",
    "plt.title(\"Regression Fit: Actual vs Predicted\")\n",
    "plt.xlabel(\"Actual G3\")\n",
    "plt.ylabel(\"Predicted G3\")\n",
    "\n",
    "\n",
    "# Show plots.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfda83d-6e4e-48b1-9ec4-d76d892d301c",
   "metadata": {},
   "source": [
    "### üìä Interpretation \n",
    "\n",
    "The **residuals distribution** indicate that errors are randomly distributed. \n",
    "\n",
    "- The model does not under- or over-fitting\n",
    "- When the residuals follow a normal distribution, the model fits well\n",
    "- If there is **skewness** or too heavy tails, it may suggest non-linear relationship not captured by the model\n",
    "\n",
    "The **regression fit** compares actual vs. predicted values, with the red dashed line representing a perfect fit. \n",
    "\n",
    "- If points closely follow the line, predictions are accurate\n",
    "- but if points scatte deviating the line, the relationship may not be truly linear, indicating limited predictive power (see the previous result when using only `studytime` as predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
