{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db7e7696-f781-4d68-ae28-8bfe6d293203",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Classification is one of fundamental tasks in the supervised machine learning. The goal is basically to train classifier model with the labelled dataset such that the model is able to categorize unseen data into predefined class. The classification algoritms create so-called mapping functions that relate the input spaces to output variables.\n",
    "\n",
    "Remember that in the regression task, the model is trained to predict continuous target variable. Meanwhile, the model in classification task is trained to predict discrete values (i.e., label or class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9d4ab-aafd-4adb-9155-df5533d239aa",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a99079-381f-47e2-b367-ef459b5d17ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30826b-57d6-49b1-ac99-c51d7aaabc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334641dc-a02d-47c4-8303-0b979c06c56c",
   "metadata": {},
   "source": [
    "## Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad76f6-6e8d-41b1-a041-2d1bac548fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5bbd9-dd48-4345-aff0-10a9a3ea711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adade482-238d-4ae5-8fe0-f3c2bb8a8aff",
   "metadata": {},
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2399b1-4c1b-4322-93f1-5fa67259886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe and add target class to the wine data\n",
    "df = pd.DataFrame(wine.data)\n",
    "df['target'] = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057d4d9-43e3-4338-967c-88e2a629acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b4323-7f16-4aa3-9cf0-0e67c14d6bdd",
   "metadata": {},
   "source": [
    "> It is noteworthy that before performing any classification task, make sure that the target class are **balance**.\n",
    ">\n",
    "> If you have any **imbalanced** class, you need to take additional step for **resampling** the train dataset.\n",
    ">\n",
    "> The following plot shows that the target classes have relatively imbalanced count. But let's try to use them and see how the models perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e467b5-9ce2-4871-912d-7c30208e1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16bc39-d549-4f1f-8c86-c6e5f9e6034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca076c4-8324-4eb8-bf34-16f3c9512dc4",
   "metadata": {},
   "source": [
    "> `Pairplot` shows marginal distribution of the data in each column, indicated by histogram along the diagonal. The scatter pairs the data distribution between two corresponding column. See this [link](https://seaborn.pydata.org/generated/seaborn.pairplot.html) for further information of pairplot.\n",
    ">\n",
    "> **Double click** the plot to make it larger.\n",
    ">\n",
    "> Try the following code and see what changes!\n",
    "\n",
    "```python\n",
    "sns.pairplot(data=df, hue='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9c670-bd61-4926-8b0c-0c2252ee13f1",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "Define predictor and target variables. Split dataset into train and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644205e8-fc62-4e1b-92d2-2b97c868b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = wine.data # feature for predictor\n",
    "y = wine.target # target to predict\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfa65e2-9f61-45c9-9224-13ea8698fae2",
   "metadata": {},
   "source": [
    "## Train the classifier model\n",
    "\n",
    "We train three different classifer including [KNN](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification), [Complement Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#complement-naive-bayes), and [SVM](https://scikit-learn.org/stable/modules/svm.html#classification). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb1a78f-0001-4e7c-afb7-f389b42f4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0035b-f2aa-40bc-a469-1e40e7bc8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "cnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c1fec-cc37-4a48-a108-0030b3290507",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=42, probability=False, kernel='rbf', decision_function_shape='ovo', C=2)\n",
    "svm.fit(X_train, y_train)\n",
    "svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfe5cf7-674a-4b54-99b7-c86a79bee080",
   "metadata": {},
   "source": [
    "> For multi-class classification, it is common to use `ovo` in the `decision_function_shape` parameter. The `C` value refers to regularization parameter, preventing the risk of overfitting. See [here](https://scikit-learn.org/stable/modules/svm.html#multi-class-classification) for further explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a878e0b-bb9a-4864-a6ca-383bc95e5433",
   "metadata": {},
   "source": [
    "## 📊 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4a26f-0fc1-4c3f-a9c0-6263bb224d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, ConfusionMatrixDisplay\n",
    "\n",
    "# predict using knn\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_knn))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(knn, \n",
    "                                      X_test, \n",
    "                                      y_test, \n",
    "                                      display_labels=wine.target_names, \n",
    "                                      cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d12df-f0a0-415d-a5f9-d272c6dd8f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using gnb\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_cnb))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(cnb, \n",
    "                                      X_test, \n",
    "                                      y_test, \n",
    "                                      display_labels=wine.target_names, \n",
    "                                      cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0923e6-a44c-4b35-9688-6aa0d6f68a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using svm\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_svm))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(svm, \n",
    "                                      X_test, \n",
    "                                      y_test, \n",
    "                                      display_labels=wine.target_names, \n",
    "                                      cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662ae9b-d415-41a8-989e-eee6e1ef6d19",
   "metadata": {},
   "source": [
    "## 🧠 Which one is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d629e1-2c3a-4525-99b8-81bee26d0e06",
   "metadata": {},
   "source": [
    "**KNN**\n",
    "\n",
    "- Performs well on class 0, moderately on class 1, and poorly on class 2.\n",
    "- Overall **accuracy** is 0.74.\n",
    "- Likely struggles with class imbalance.\n",
    "- Sensitive to the choice of $k$ and feature scaling.\n",
    "\n",
    "**Complement Naive Bayes**\n",
    "\n",
    "- Performs perfectly on class 2 and moderately similar on class 0 and 1.\n",
    "- Possibly due to normally distributed features.\n",
    "- Overall **accuracy** is 0.67, the poorest among the other models.\n",
    "\n",
    "**Support Vector Machine (SVM)**\n",
    "\n",
    "- Excellent on class 0, good performance on class 1, but poor on class 2.\n",
    "- Overall **accuracy** is 0.78, the best model so far.\n",
    "- Likely has trouble separating class 2 due to overlapping decision boundaries.\n",
    "- May benefit from kernel tuning or class weighting.\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> \n",
    "<p>Both KNN & SVM struggle to deal with class 2. Possibly due to class imbalance.</p>\n",
    "<p>Complement NB is the underperformed model. This model is not generalize well to unseen data. </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6a437-cb45-400e-ae03-387cf05353a8",
   "metadata": {},
   "source": [
    "## Resampling class for balancing\n",
    "\n",
    "There are many techniques for resampling dataset. We will use [SMOTE](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTE.html) - 'Synthetic Minority Over-sampling Technique' to balance the dataset. \n",
    "\n",
    "Resampling will be performed only on **train** set, thus the proportion of class in the **test** set is maintained.\n",
    "\n",
    "First, make sure that the package is already installed by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c81f9fd-dfc0-4831-ab05-cda85789e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618a3c8-3f7c-464c-ad67-a7cbda1ac72a",
   "metadata": {},
   "source": [
    "> Run this code if it is not installed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0822ed-47aa-4723-ad8f-9d28f7f26d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c6585-2cd4-4d36-9276-a9193e869d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "resample = SMOTE()\n",
    "X_train_resampled, y_train_resampled = resample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d1287-aefa-464c-a17b-9f82e5f4eaf9",
   "metadata": {},
   "source": [
    "### Check the class proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f20f6b-e827-45c3-941f-02a6cc041b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total initial sample:', len(X_train))\n",
    "# check the target class proportion\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45faf5a4-e028-4465-bbbc-fa8879387f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total sample after resampling:', len(X_train_resampled))\n",
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c496b-36d7-4fe9-9f35-3927d94a43b2",
   "metadata": {},
   "source": [
    "> As we can see that before resampling the dataset contains **124** samples with **different** `count` on each target class.\n",
    ">\n",
    "> After resampling, we see that the proportion on each class is now balanced, **50 sample each class**, with new total sample of **150** records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0474271-496b-4bec-b78b-6c30e756f542",
   "metadata": {},
   "source": [
    "## 🔍 Retrain the model\n",
    "Let's train the model with new resampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03057896-7444-4d77-8b9f-fa6eac378154",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_resampled = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# predict using knn\n",
    "y_pred_knn_resampled = knn_resampled.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_knn_resampled))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(knn_resampled, \n",
    "                                      X_test, \n",
    "                                      y_test, \n",
    "                                      display_labels=wine.target_names, \n",
    "                                      cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b1d6c-c58d-475d-a4f7-64c41ee35d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb_resampled = ComplementNB()\n",
    "cnb_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# predict using knn\n",
    "y_pred_cnb_resampled = cnb_resampled.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_cnb_resampled))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(cnb_resampled, \n",
    "                                      X_test, \n",
    "                                      y_test, \n",
    "                                      display_labels=wine.target_names, \n",
    "                                      cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84c6a0-27b9-40a2-85e7-4401c0b3895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_resampled = SVC(random_state=42, decision_function_shape='ovo', C=2,\n",
    "                    probability=False, kernel='rbf')\n",
    "svm_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# predict using knn\n",
    "y_pred_svm_resampled = svm_resampled.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_svm_resampled))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(svm_resampled, \n",
    "                                      X_test, \n",
    "                                      y_test, \n",
    "                                      display_labels=wine.target_names, \n",
    "                                      cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822d969-6452-41ce-a394-ce3de5d6494e",
   "metadata": {},
   "source": [
    "> As we can see that the performance of all models are improved after balancing the sample.\n",
    ">\n",
    "> The accuracy of each model:\n",
    "> - **KNN**: 0.74 → 0.76\n",
    "> - **CNB**: 0.67 → 0.78 (highest improvement - 16%)\n",
    "> - **SVM**: 0.78 → 0.80 (still the best performing model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
